{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d4bec4",
   "metadata": {},
   "source": [
    "## Data pereparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86d25b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets #dataset within Pytorch\n",
    "                                            #transforms is what we will apply to the data\n",
    "import torch.utils.data as tud\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ea73c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(\"\", train=True, download=True,   #first spot specifies where we want the data to go \"\" means we want it to go locally\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))  #here we use the \n",
    "#transform to tensor because the MNIST data isn't in tensor format\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False, download=True,\n",
    "                     transform = transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99dbe4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = tud.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = tud.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94e6c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([0, 7, 7, 3, 5, 8, 0, 4, 8, 6])]\n"
     ]
    }
   ],
   "source": [
    "#iterating over one batch of ten samples using break to stop at the first batch\n",
    "#labels at \"tensor\"\n",
    "\n",
    "for data in trainset:\n",
    "    print(data)\n",
    "    break\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9a4fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]   #data[0th tensor of tensors, 0th element of that tensor] \n",
    "                                #so data[0][something] refers to the images and data[1][something]\n",
    "                                #refers to the labels\n",
    "\n",
    "#print(data[0][0])     \n",
    "print(data[0][1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44c614fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ef0692c5e0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#to plot the image with plt.imshow we need to get rid of the third grey scale dimention, \n",
    "#i.e. reshaping with view\n",
    "\n",
    "plt.imshow(data[0][0].view(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc41516",
   "metadata": {},
   "source": [
    "## Balancing the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b5e7c",
   "metadata": {},
   "source": [
    "Motiation: is that the presece of a prominent feature will force the model to overfit to that\n",
    "dominant feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb75621e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "#checking the samples for each label\n",
    "\n",
    "tot = 0\n",
    "counter = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    samples, labels = data \n",
    "    for i in labels:\n",
    "        counter[int(i)]+= 1\n",
    "        tot+=1\n",
    "        \n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d05861a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 9.871666666666666%\n",
      "1: 11.236666666666666%\n",
      "2: 9.93%\n",
      "3: 10.218333333333334%\n",
      "4: 9.736666666666666%\n",
      "5: 9.035%\n",
      "6: 9.863333333333333%\n",
      "7: 10.441666666666666%\n",
      "8: 9.751666666666667%\n",
      "9: 9.915000000000001%\n"
     ]
    }
   ],
   "source": [
    "for i in counter:  #looping through the elements in counter   \n",
    "    print(f\"{i}: {counter[i]/tot*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716bff8a",
   "metadata": {},
   "source": [
    "data is balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b8cc7e",
   "metadata": {},
   "source": [
    "## Building the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn  #the OOP (initializing parameters)\n",
    "import torch.nn.functional as F #funtions, passing parameters\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
